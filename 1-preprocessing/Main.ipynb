{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OrdinalEncoder, LabelEncoder, OneHotEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = pd.read_csv('./credit+approval/crx.data', header=None, na_values=\"?\")\n",
    "cont_attr = [1,2,7,10,13,14]\n",
    "dist_attr = []\n",
    "for i in range(15):\n",
    "    if i not in cont_attr:\n",
    "        dist_attr.append(i)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Handling Missing Values\n",
    "+ For Continuous Columns we use the __mean__\n",
    "+ For Discrete Columns we use the __mod__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with Missing Values in Machine Learning (copilot response)\n",
    "\n",
    "Handling missing values is an important step in the data preprocessing phase of a machine learning project. Here are some common methods to deal with missing values:\n",
    "\n",
    "### 1. Remove Missing Values\n",
    "\n",
    "- **Remove Rows:** If the dataset has a small number of missing values, you can simply remove those rows.\n",
    "\n",
    "    ```python\n",
    "    # Remove rows with any missing values\n",
    "    data_cleaned = data.dropna()\n",
    "    ```\n",
    "\n",
    "### 2. Impute Missing Values\n",
    "\n",
    "- **Mean/Median/Mode Imputation:** Replace missing values with the mean, median, or mode of the respective column\n",
    "\n",
    "    ```python\n",
    "    from sklearn.impute import SimpleImputer\n",
    "\n",
    "    # Replace missing values with mean\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    data_imputed = mean_imputer.fit_transform(data)\n",
    "\n",
    "    # Replace missing values with median\n",
    "    median_imputer = SimpleImputer(strategy='median')\n",
    "    data_imputed = median_imputer.fit_transform(data)\n",
    "\n",
    "    # Replace missing values with mode\n",
    "    mode_imputer = SimpleImputer(strategy='most_frequent')\n",
    "    data_imputed = mode_imputer.fit_transform(data)\n",
    "\n",
    "    ```\n",
    "- **Constant Value Imputation:** Replace missing values with a specific constant value, such as 0 or -1.\n",
    "### 3. Predict Missing Values\n",
    "\n",
    "- **Use Machine Learning Models:** Predict missing values based on other features in the dataset.\n",
    "    ```python \n",
    "    from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "    # Assume 'data' is a DataFrame and we want to predict missing values in 'target_column'\n",
    "    missing_data = data[data['target_column'].isnull()]\n",
    "    available_data = data[data['target_column'].notnull()]\n",
    "\n",
    "    # Train a model on available data\n",
    "    model = RandomForestRegressor()\n",
    "    model.fit(available_data.drop('target_column', axis=1), available_data['target_column'])\n",
    "\n",
    "    # Predict missing values\n",
    "    missing_data['target_column'] = model.predict(missing_data.drop('target_column', axis=1))\n",
    "\n",
    "    # Combine the datasets back together\n",
    "    data_imputed = pd.concat([available_data, missing_data])\n",
    "\n",
    "    ```\n",
    "### 4. Use Algorithms That Support Missing Values\n",
    "\n",
    "- Certain algorithms like __decision__ trees and __XGBoost__ can handle missing values natively, without requiring explicit imputation.\n",
    "\n",
    "    ```python \n",
    "    from xgboost import XGBClassifier\n",
    "\n",
    "    # Train an XGBoost model on data with missing values\n",
    "    model = XGBClassifier()\n",
    "    model.fit(X_train, y_train)\n",
    "    ```\n",
    "### 5. Create a Missing Indicator\n",
    "\n",
    "- Create an additional feature indicating whether a value was missing.\n",
    "    ```python \n",
    "    # Create an indicator column for missing values\n",
    "    data['missing_indicator'] = data['target_column'].isnull().astype(int)\n",
    "\n",
    "    # Impute missing values after creating the indicator\n",
    "    mean_imputer = SimpleImputer(strategy='mean')\n",
    "    data['target_column'] = mean_imputer.fit_transform(data[['target_column']])\n",
    "\n",
    "    ```\n",
    "\n",
    "- **Conclusion**\n",
    "\n",
    "        Handling missing values appropriately can significantly improve the performance of your machine learning models. The method you choose depends on the nature of your data and the specific requirements of your project. Always ensure to explore and understand the impact of missing values on your dataset before deciding on the best strategy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Preprocessing: 0     12\n",
      "1     12\n",
      "2      0\n",
      "3      6\n",
      "4      6\n",
      "5      9\n",
      "6      9\n",
      "7      0\n",
      "8      0\n",
      "9      0\n",
      "10     0\n",
      "11     0\n",
      "12     0\n",
      "13    13\n",
      "14     0\n",
      "15     0\n",
      "dtype: int64\n",
      "After Preprocessing: 0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    0\n",
      "12    0\n",
      "13    0\n",
      "14    0\n",
      "15    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Continuous => mean\n",
    "# Disctrete => mod\n",
    "print(\"Before Preprocessing:\",raw_data.isna().sum())\n",
    "for index in range(15):\n",
    "    if index in cont_attr:\n",
    "        _mean = raw_data[index].mean()\n",
    "        raw_data[index] = raw_data[index].replace(math.nan, _mean)\n",
    "        continue\n",
    "    _mode = raw_data[index].mode()[0]\n",
    "    raw_data[index] = raw_data[index].replace(math.nan, _mode)\n",
    "\n",
    "print(\"After Preprocessing:\",raw_data.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Normalization\n",
    "\n",
    "\n",
    "1. min_max_scale method: \n",
    "    $$ x_{scale} = \\frac{x-x_{min}}{x_{max}-x_{min}}$$\n",
    "\n",
    "2. mean_scale method:\n",
    "    $$ x_{scale} = \\frac{x-x_{mean}}{x_{max}-x_{mean}}$$\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why Does Normalization Take Place in Machine Learning? (Copilot response to this question)\n",
    "\n",
    "Normalization is a crucial step in the machine learning process for several key reasons:\n",
    "\n",
    "1. **Improved Convergence During Training:**\n",
    "   - **Gradient Descent:** Algorithms that use gradient descent for optimization, such as neural networks, benefit significantly from normalized data. It helps in faster convergence and prevents the algorithm from getting stuck in local minima.\n",
    "\n",
    "2. **Equal Contribution of Features:**\n",
    "   - **Feature Scaling:** When features in a dataset have different ranges, those with larger ranges can dominate the learning algorithm, making it difficult for the model to learn from other features. Normalization ensures that all features contribute equally to the model's performance.\n",
    "\n",
    "3. **Reduced Sensitivity to Feature Scaling:**\n",
    "   - **Distance Metrics:** Algorithms that use distance metrics, such as k-Nearest Neighbors (k-NN) and Support Vector Machines (SVM), are sensitive to the scale of features. Normalization ensures that each feature contributes equally to the distance computation, improving the accuracy of these algorithms.\n",
    "\n",
    "4. **Enhanced Model Performance:**\n",
    "   - **Consistency:** Normalized data often lead to better performance across various machine learning models. Consistently scaled data help the algorithms learn more effectively and make better predictions.\n",
    "\n",
    "5. **Prevents Bias:**\n",
    "   - **Bias Reduction:** Without normalization, the learning algorithm might be biased towards features with higher magnitudes. Normalization ensures that no single feature dominates the learning process, leading to more balanced and unbiased models.\n",
    "\n",
    "### Common Normalization Techniques\n",
    "\n",
    "1. **Min-Max Scaling:**\n",
    "   - Rescales the feature to a fixed range, typically \\([0, 1]\\) or \\([-1, 1]\\).\n",
    "\n",
    "      ```python\n",
    "      from sklearn.preprocessing import MinMaxScaler\n",
    "      scaler = MinMaxScaler()\n",
    "      normalized_data = scaler.fit_transform(data)\n",
    "      ```\n",
    "\n",
    "2. **Standardization (Z-Score Normalization):**\n",
    "   - Centers the data around the mean with a unit standard deviation.\n",
    "\n",
    "      ``` python \n",
    "      from sklearn.preprocessing import StandardScaler \n",
    "      scaler = StandardScaler() \n",
    "      standardized_data = scaler.fit_transform(data) \n",
    "      ```\n",
    "3. **Robust Scaler:**\n",
    "   - Uses median and interquartile range for scaling, making it robust to outliers.\n",
    "\n",
    "      ``` python \n",
    "      from sklearn.preprocessing import RobustScaler \n",
    "      scaler = RobustScaler() \n",
    "      robust_scaled_data = scaler.fit_transform(data) \n",
    "      ```\n",
    "\n",
    "         By normalizing your data, you ensure that your machine learning model performs optimally and learns effectively from the features provided. It's a critical preprocessing step that can significantly impact the performance and accuracy of your models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====\n",
      "before index: 1-min: 13.75-max: 80.25\n",
      "after index: 1-min: 0.0-max: 1.0\n",
      "=====\n",
      "before index: 2-min: 0.0-max: 28.0\n",
      "after index: 2-min: 0.0-max: 1.0\n",
      "=====\n",
      "before index: 7-min: 0.0-max: 28.5\n",
      "after index: 7-min: 0.0-max: 1.0\n",
      "=====\n",
      "before index: 10-min: 0-max: 67\n",
      "after index: 10-min: 0.0-max: 1.0\n",
      "=====\n",
      "before index: 13-min: 0.0-max: 2000.0\n",
      "after index: 13-min: 0.0-max: 1.0\n",
      "=====\n",
      "before index: 14-min: 0-max: 100000\n",
      "after index: 14-min: 0.0-max: 1.0\n"
     ]
    }
   ],
   "source": [
    "for index in cont_attr:\n",
    "    x = raw_data[index]\n",
    "    x_min = raw_data[index].min()\n",
    "    x_max = raw_data[index].max()\n",
    "    print(\"=====\")\n",
    "    print(\"before index: {0}-min: {1}-max: {2}\".format(index, x_min, x_max))\n",
    "    raw_data[index] = (x-x_min)/(x_max-x_min)\n",
    "\n",
    "    x_min = raw_data[index].min()\n",
    "    x_max = raw_data[index].max()\n",
    "    print(\"after index: {0}-min: {1}-max: {2}\".format(index, x_min, x_max))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a</td>\n",
       "      <td>0.675489</td>\n",
       "      <td>0.159286</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.00560</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>a</td>\n",
       "      <td>0.161654</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>q</td>\n",
       "      <td>h</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.00824</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>0.211729</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>t</td>\n",
       "      <td>t</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b</td>\n",
       "      <td>0.096541</td>\n",
       "      <td>0.200893</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>t</td>\n",
       "      <td>f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>b</td>\n",
       "      <td>0.110226</td>\n",
       "      <td>0.360179</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>e</td>\n",
       "      <td>h</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>a</td>\n",
       "      <td>0.134135</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>v</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.00394</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>a</td>\n",
       "      <td>0.172932</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>y</td>\n",
       "      <td>p</td>\n",
       "      <td>ff</td>\n",
       "      <td>ff</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>f</td>\n",
       "      <td>t</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>b</td>\n",
       "      <td>0.062707</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>aa</td>\n",
       "      <td>v</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>f</td>\n",
       "      <td>g</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>b</td>\n",
       "      <td>0.319549</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>u</td>\n",
       "      <td>g</td>\n",
       "      <td>c</td>\n",
       "      <td>h</td>\n",
       "      <td>0.290877</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>t</td>\n",
       "      <td>g</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    0         1         2  3  4   5   6         7  8  9         10 11 12  \\\n",
       "0    b  0.256842  0.000000  u  g   w   v  0.043860  t  t  0.014925  f  g   \n",
       "1    a  0.675489  0.159286  u  g   q   h  0.106667  t  t  0.089552  f  g   \n",
       "2    a  0.161654  0.017857  u  g   q   h  0.052632  t  f  0.000000  f  g   \n",
       "3    b  0.211729  0.055000  u  g   w   v  0.131579  t  t  0.074627  t  g   \n",
       "4    b  0.096541  0.200893  u  g   w   v  0.060000  t  f  0.000000  f  s   \n",
       "..  ..       ...       ... .. ..  ..  ..       ... .. ..       ... .. ..   \n",
       "685  b  0.110226  0.360179  y  p   e   h  0.043860  f  f  0.000000  f  g   \n",
       "686  a  0.134135  0.026786  u  g   c   v  0.070175  f  t  0.029851  t  g   \n",
       "687  a  0.172932  0.482143  y  p  ff  ff  0.070175  f  t  0.014925  t  g   \n",
       "688  b  0.062707  0.007321  u  g  aa   v  0.001404  f  f  0.000000  f  g   \n",
       "689  b  0.319549  0.120536  u  g   c   h  0.290877  f  f  0.000000  t  g   \n",
       "\n",
       "         13       14 15  \n",
       "0    0.1010  0.00000  +  \n",
       "1    0.0215  0.00560  +  \n",
       "2    0.1400  0.00824  +  \n",
       "3    0.0500  0.00003  +  \n",
       "4    0.0600  0.00000  +  \n",
       "..      ...      ... ..  \n",
       "685  0.1300  0.00000  -  \n",
       "686  0.1000  0.00394  -  \n",
       "687  0.1000  0.00001  -  \n",
       "688  0.1400  0.00750  -  \n",
       "689  0.0000  0.00000  -  \n",
       "\n",
       "[690 rows x 16 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  using minmaxScaler\n",
    "\n",
    "min_max_scaler = MinMaxScaler()\n",
    "x = raw_data[cont_attr].values\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "\n",
    "normalized = pd.DataFrame(x_scaled, columns=cont_attr, index=raw_data.index)\n",
    "raw_data[cont_attr] = normalized\n",
    "raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Why and How Nominal Variables Convert into Numerical Values in Machine Learning (copilot response)\n",
    "\n",
    "### Why Convert Nominal Variables?\n",
    "\n",
    "Nominal variables, also known as categorical variables, represent distinct categories or labels without any intrinsic order. Examples include gender, country, or color. Converting these variables into numerical values is essential for the following reasons:\n",
    "\n",
    "1. **Compatibility with Algorithms:**\n",
    "   - Many machine learning algorithms require numerical input. Algorithms such as linear regression, logistic regression, and neural networks cannot process categorical data directly.\n",
    "\n",
    "2. **Improved Performance:**\n",
    "   - Numerical encoding of categorical variables often leads to better model performance by enabling the algorithms to find meaningful patterns and relationships.\n",
    "\n",
    "3. **Distance Metrics:**\n",
    "   - Algorithms that rely on distance metrics (e.g., k-Nearest Neighbors, k-Means clustering) need numerical values to calculate distances between data points.\n",
    "\n",
    "### How to Convert Nominal Variables\n",
    "\n",
    "Several techniques can be used to convert nominal variables into numerical values:\n",
    "\n",
    "#### 1. **Label Encoding**\n",
    "\n",
    "Label encoding assigns a unique integer to each category. It is suitable for ordinal data where the categories have an inherent order, but can introduce unintended ordinal relationships for nominal data.\n",
    "\n",
    "```python\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Example data\n",
    "data = ['red', 'blue', 'green', 'blue', 'green', 'red']\n",
    "\n",
    "# Initialize the LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = label_encoder.fit_transform(data)\n",
    "\n",
    "print(encoded_data)\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. **One-Hot Encoding**\n",
    "\n",
    "One-hot encoding creates binary columns for each category, ensuring no ordinal relationships are introduced. It is suitable for nominal data.\n",
    "\n",
    "```python \n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({'color': ['red', 'blue', 'green', 'blue', 'green', 'red']})\n",
    "\n",
    "# Perform one-hot encoding\n",
    "one_hot_encoded_data = pd.get_dummies(data, columns=['color'])\n",
    "\n",
    "print(one_hot_encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\none_enc = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\\nnew_raw_data = one_enc.fit_transform(raw_data[dist_attr]) \\n# print(new_raw_data.shape)\\nnew_raw_data_df = pd.DataFrame(new_raw_data)\\n\\nnew_raw_data_df.index = raw_data.index\\nraw_data = raw_data.drop(dist_attr, axis=1)\\n\\nX= pd.concat([new_raw_data_df, raw_data], axis=1)\\n\\nX\\n\\n\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# using numpy arrays\n",
    "'''\n",
    "one_enc = OneHotEncoder(handle_unknown='ignore',sparse_output=False)\n",
    "new_raw_data = one_enc.fit_transform(raw_data[dist_attr]) \n",
    "# print(new_raw_data.shape)\n",
    "new_raw_data_df = pd.DataFrame(new_raw_data)\n",
    "\n",
    "new_raw_data_df.index = raw_data.index\n",
    "raw_data = raw_data.drop(dist_attr, axis=1)\n",
    "\n",
    "X= pd.concat([new_raw_data_df, raw_data], axis=1)\n",
    "\n",
    "X\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>7</th>\n",
       "      <th>10</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>0_a</th>\n",
       "      <th>0_b</th>\n",
       "      <th>3_l</th>\n",
       "      <th>...</th>\n",
       "      <th>6_z</th>\n",
       "      <th>8_f</th>\n",
       "      <th>8_t</th>\n",
       "      <th>9_f</th>\n",
       "      <th>9_t</th>\n",
       "      <th>11_f</th>\n",
       "      <th>11_t</th>\n",
       "      <th>12_g</th>\n",
       "      <th>12_p</th>\n",
       "      <th>12_s</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.256842</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.1010</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.675489</td>\n",
       "      <td>0.159286</td>\n",
       "      <td>0.106667</td>\n",
       "      <td>0.089552</td>\n",
       "      <td>0.0215</td>\n",
       "      <td>0.00560</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.161654</td>\n",
       "      <td>0.017857</td>\n",
       "      <td>0.052632</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.00824</td>\n",
       "      <td>+</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.211729</td>\n",
       "      <td>0.055000</td>\n",
       "      <td>0.131579</td>\n",
       "      <td>0.074627</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.00003</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.096541</td>\n",
       "      <td>0.200893</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>+</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>0.110226</td>\n",
       "      <td>0.360179</td>\n",
       "      <td>0.043860</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>686</th>\n",
       "      <td>0.134135</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.029851</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.00394</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>687</th>\n",
       "      <td>0.172932</td>\n",
       "      <td>0.482143</td>\n",
       "      <td>0.070175</td>\n",
       "      <td>0.014925</td>\n",
       "      <td>0.1000</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>-</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>688</th>\n",
       "      <td>0.062707</td>\n",
       "      <td>0.007321</td>\n",
       "      <td>0.001404</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.00750</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>689</th>\n",
       "      <td>0.319549</td>\n",
       "      <td>0.120536</td>\n",
       "      <td>0.290877</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>-</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>690 rows × 47 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            1         2         7        10      13       14 15    0_a    0_b  \\\n",
       "0    0.256842  0.000000  0.043860  0.014925  0.1010  0.00000  +  False   True   \n",
       "1    0.675489  0.159286  0.106667  0.089552  0.0215  0.00560  +   True  False   \n",
       "2    0.161654  0.017857  0.052632  0.000000  0.1400  0.00824  +   True  False   \n",
       "3    0.211729  0.055000  0.131579  0.074627  0.0500  0.00003  +  False   True   \n",
       "4    0.096541  0.200893  0.060000  0.000000  0.0600  0.00000  +  False   True   \n",
       "..        ...       ...       ...       ...     ...      ... ..    ...    ...   \n",
       "685  0.110226  0.360179  0.043860  0.000000  0.1300  0.00000  -  False   True   \n",
       "686  0.134135  0.026786  0.070175  0.029851  0.1000  0.00394  -   True  False   \n",
       "687  0.172932  0.482143  0.070175  0.014925  0.1000  0.00001  -   True  False   \n",
       "688  0.062707  0.007321  0.001404  0.000000  0.1400  0.00750  -  False   True   \n",
       "689  0.319549  0.120536  0.290877  0.000000  0.0000  0.00000  -  False   True   \n",
       "\n",
       "       3_l  ...    6_z    8_f    8_t    9_f    9_t   11_f   11_t   12_g  \\\n",
       "0    False  ...  False  False   True  False   True   True  False   True   \n",
       "1    False  ...  False  False   True  False   True   True  False   True   \n",
       "2    False  ...  False  False   True   True  False   True  False   True   \n",
       "3    False  ...  False  False   True  False   True  False   True   True   \n",
       "4    False  ...  False  False   True   True  False   True  False  False   \n",
       "..     ...  ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "685  False  ...  False   True  False   True  False   True  False   True   \n",
       "686  False  ...  False   True  False  False   True  False   True   True   \n",
       "687  False  ...  False   True  False  False   True  False   True   True   \n",
       "688  False  ...  False   True  False   True  False   True  False   True   \n",
       "689  False  ...  False   True  False   True  False  False   True   True   \n",
       "\n",
       "      12_p   12_s  \n",
       "0    False  False  \n",
       "1    False  False  \n",
       "2    False  False  \n",
       "3    False  False  \n",
       "4    False   True  \n",
       "..     ...    ...  \n",
       "685  False  False  \n",
       "686  False  False  \n",
       "687  False  False  \n",
       "688  False  False  \n",
       "689  False  False  \n",
       "\n",
       "[690 rows x 47 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# using pandas built-in functions \n",
    "# Comment the last cell and uncomment the following code\n",
    "\n",
    "one_hot = pd.get_dummies(raw_data[dist_attr])\n",
    "raw_data = raw_data.drop(dist_attr, axis=1)\n",
    "X = raw_data.join(one_hot)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. **Ordinal Encoding**\n",
    "\n",
    "Ordinal encoding assigns integer values to categories based on a specified order. It is appropriate for ordinal data where the order of categories matters.\n",
    "\n",
    "```python \n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "# Example data with an inherent order\n",
    "data = pd.DataFrame({'size': ['small', 'medium', 'large', 'medium', 'small']})\n",
    "\n",
    "# Define the order of categories\n",
    "categories = [['small', 'medium', 'large']]\n",
    "\n",
    "# Initialize the OrdinalEncoder\n",
    "ordinal_encoder = OrdinalEncoder(categories=categories)\n",
    "\n",
    "# Fit and transform the data\n",
    "encoded_data = ordinal_encoder.fit_transform(data[['size']])\n",
    "\n",
    "print(encoded_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. **Target Encoding**\n",
    "Target encoding replaces each category with the mean of the target variable for that category. It can be useful for high-cardinality categorical variables but may introduce data leakage if not applied carefully.\n",
    "\n",
    "```python \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Example data\n",
    "data = pd.DataFrame({'category': ['A', 'B', 'A', 'B', 'A'],\n",
    "                     'target': [1, 2, 3, 4, 5]})\n",
    "\n",
    "# Calculate the mean target for each category\n",
    "target_mean = data.groupby('category')['target'].mean()\n",
    "\n",
    "# Replace categories with the mean target value\n",
    "data['category_encoded'] = data['category'].map(target_mean)\n",
    "\n",
    "print(data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(690, 46) (690,)\n",
      "(138, 46) (552, 46)\n"
     ]
    }
   ],
   "source": [
    "# splitting the dataset\n",
    "\n",
    "Y = np.array(X.pop(15))\n",
    "X = np.array(X)\n",
    "\n",
    "print(X.shape, Y.shape)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X,Y, test_size=.2)\n",
    "print(X_test.shape, X_train.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
